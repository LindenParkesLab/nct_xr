{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:08:53.684862Z",
     "start_time": "2023-11-25T18:08:53.483907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 8})\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "import seaborn as sns\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "sys.path.extend([r'/home/lindenmp/research_projects/snaplab_tools'])\n",
    "sys.path.extend([r'/home/lindenmp/research_projects/nctpy/src'])\n",
    "\n",
    "# import nctpy functions\n",
    "from snaplab_tools.plotting.plotting import categorical_kde_plot, reg_plot, brain_scatter_plot\n",
    "from snaplab_tools.plotting.utils import get_my_colors, get_p_val_string\n",
    "from nctpy.utils import matrix_normalization\n",
    "from null_models.geomsurr import geomsurr\n",
    "\n",
    "from brainsmash.mapgen.base import Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where data is stored\n",
    "indir = '/home/lindenmp/research_projects/nct_xr/data'\n",
    "which_data = 'HCPYA'\n",
    "# which_data = 'macaque'\n",
    "outdir = '/home/lindenmp/research_projects/nct_xr/results/{0}'.format(which_data)\n",
    "\n",
    "atlas = 'Schaefer4007'\n",
    "if atlas == 'Schaefer4007':\n",
    "    n_parcels = 400\n",
    "elif atlas == 'Schaefer2007':\n",
    "    n_parcels = 200\n",
    "elif atlas == 'Schaefer1007':\n",
    "    n_parcels = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_file = '{0}_{1}_Am.npy'.format(which_data, atlas)\n",
    "A = np.load(os.path.join(indir, A_file))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.heatmap(A, ax=ax, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rsfMRI clusters\n",
    "k = 7\n",
    "n_states = k\n",
    "if which_data == 'macaque':\n",
    "    fmri_clusters_file = '{0}_fmri_clusters_k-{1}.npy'.format(which_data, k)\n",
    "else:\n",
    "    fmri_clusters_file = '{0}_{1}_rsts_fmri_clusters_k-{2}.npy'.format(which_data, atlas, k)\n",
    "fmri_clusters = np.load(os.path.join(outdir, fmri_clusters_file), allow_pickle=True).item()\n",
    "print(fmri_clusters.keys())\n",
    "centroids = fmri_clusters['centroids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cluster centers. These represent dominant patterns of recurrent activity over time\n",
    "if which_data == 'macaque':\n",
    "    parc_centroids = pd.read_csv(os.path.join(indir, 'macaque', 'MarkovCC12_M132_182-area.32k_fs_LR_mean_vertex.csv'), index_col=0)\n",
    "else:\n",
    "    parc_centroids = pd.read_csv(os.path.join(indir, 'Schaefer2018_{0}Parcels_7Networks_order_FSLMNI152_1mm.Centroid_RAS.csv'.format(n_parcels)), index_col=1)\n",
    "    parc_centroids.drop(columns=['ROI Label'], inplace=True)\n",
    "parc_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = distance.pdist(\n",
    "    parc_centroids, \"euclidean\"\n",
    ")  # get euclidean distances between nodes\n",
    "distance_matrix = distance.squareform(distance_matrix)  # reshape to square matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.heatmap(distance_matrix, ax=ax, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run permutation\n",
    "n_perms = 5000  # number of permutations\n",
    "n_nodes = A.shape[0]\n",
    "\n",
    "# containers for null distributions\n",
    "Wwp = np.zeros((n_nodes, n_nodes, n_perms))\n",
    "Wsp = np.zeros((n_nodes, n_nodes, n_perms))\n",
    "Wssp = np.zeros((n_nodes, n_nodes, n_perms))\n",
    "\n",
    "for perm in tqdm(np.arange(n_perms)):\n",
    "    # rewire adjacency matrix using geomsurr\n",
    "    Wwp[:, :, perm], Wsp[:, :, perm], Wssp[:, :, perm] = geomsurr(W=A, D=distance_matrix, seed=perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_str = A_file.split('.')[0] + '_perm-wwp-{0}.npy'.format(n_perms)\n",
    "print(file_str)\n",
    "np.save(os.path.join(outdir, file_str), Wwp)\n",
    "\n",
    "file_str = A_file.split('.')[0] + '_perm-wsp-{0}.npy'.format(n_perms)\n",
    "print(file_str)\n",
    "np.save(os.path.join(outdir, file_str), Wsp)\n",
    "\n",
    "file_str = A_file.split('.')[0] + '_perm-wssp-{0}.npy'.format(n_perms)\n",
    "print(file_str)\n",
    "np.save(os.path.join(outdir, file_str), Wssp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_surrogates = np.zeros((n_states, n_nodes, n_perms))\n",
    "for state_idx in tqdm(np.arange(n_states)):\n",
    "    base = Base(x=centroids[state_idx, :], D=distance_matrix)\n",
    "    surrogates = base(n=n_perms)\n",
    "    centroids_surrogates[state_idx] = surrogates.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_str = fmri_clusters_file.split('.')[0] + '_brainsmash-surrogates-{1}.npy'.format(n_perms, n_perms)\n",
    "print(file_str)\n",
    "np.save(os.path.join(outdir, file_str), centroids_surrogates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted reference states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_state_surrogates = np.zeros((n_states, n_states, n_nodes, n_perms))\n",
    "# for initial_idx in tqdm(np.arange(n_states)):\n",
    "#     initial_state = centroids[initial_idx, :]\n",
    "#     for target_idx in np.arange(n_states):\n",
    "#         target_state = centroids[target_idx, :]\n",
    "#         reference_state = initial_state + ((target_state - initial_state) * 0.5)\n",
    "#         base = Base(x=reference_state, D=distance_matrix)\n",
    "#         surrogates = base(n=n_perms)\n",
    "#         ref_state_surrogates[initial_idx, target_idx] = surrogates.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_str = 'hcp_fmri_clusters_k-{0}_brainsmash-surrogates-midpoint-{1}.npy'.format(n_states, n_perms)\n",
    "# print(file_str)\n",
    "# np.save(os.path.join(outdir, file_str), ref_state_surrogates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nct_xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
