{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:08:53.684862Z",
     "start_time": "2023-11-25T18:08:53.483907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"font.size\": 8})\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "import seaborn as sns\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "sys.path.extend([r'/home/lindenmp/research_projects/snaplab_tools'])\n",
    "sys.path.extend([r'/home/lindenmp/research_projects/nctpy/src'])\n",
    "\n",
    "# import nctpy functions\n",
    "from snaplab_tools.plotting.plotting import categorical_kde_plot, reg_plot, brain_scatter_plot, null_plot, surface_plot\n",
    "from snaplab_tools.plotting.utils import get_my_colors, get_p_val_string\n",
    "from nctpy.utils import matrix_normalization\n",
    "from snaplab_tools.utils import get_schaefer_system_mask, get_null_p, get_fdr_p\n",
    "from snaplab_tools.plotting.utils import roi_to_vtx\n",
    "\n",
    "from brainsmash.mapgen.base import Base\n",
    "from src.utils import get_adj_weights\n",
    "from snaplab_tools.utils import normalize_x\n",
    "\n",
    "from snaplab_tools.derivs import compute_acf\n",
    "from nilearn.glm import first_level\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from scipy import signal\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_deflections(rest_timescales, task_timescales, nuisance_regression=False):\n",
    "    rest_timescales = rest_timescales.reshape(-1, 1)\n",
    "    task_timescales = task_timescales.reshape(-1, 1)\n",
    "\n",
    "    int_deflections = task_timescales - rest_timescales\n",
    "    \n",
    "    if nuisance_regression:\n",
    "        deflections_mean = np.mean(int_deflections)\n",
    "        \n",
    "        X = np.concatenate((rest_timescales, np.ones((rest_timescales.shape[0], 1))), axis=1)\n",
    "        beta = np.dot(np.linalg.pinv(X), int_deflections)\n",
    "        predicted = np.dot(X, beta)\n",
    "        int_deflections = int_deflections - predicted\n",
    "        # print(int_deflections.shape, predicted.shape)\n",
    "        # int_deflections += deflections_mean\n",
    "    \n",
    "    return int_deflections[:, 0]\n",
    "\n",
    "def nuis_reg(X, y, use_sklearn=False):\n",
    "    if use_sklearn:\n",
    "        if X.ndim == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(X, y)\n",
    "        predicted = regr.predict(X)\n",
    "        residuals = y - predicted\n",
    "    else:\n",
    "        beta = np.dot(np.linalg.pinv(X), y)\n",
    "        predicted = np.dot(X, beta)\n",
    "        residuals = y - predicted\n",
    "    return residuals\n",
    "\n",
    "def run_regression(df_behavior, y_var, rest_timescales, task_timescales):\n",
    "    n_nodes = rest_timescales.shape[0]\n",
    "    effect_map = pd.DataFrame(index=np.arange(n_nodes))\n",
    "    pvals = pd.DataFrame(index=np.arange(n_nodes))\n",
    "\n",
    "    for i in tqdm(np.arange(n_nodes)):\n",
    "        df_stats = pd.DataFrame(index=df_behavior.index)\n",
    "        df_stats[y_var] = df_behavior[y_var].copy()\n",
    "        df_stats[y_var].fillna(np.nanmean(df_stats[y_var]), inplace=True)\n",
    "        df_stats[y_var] = sp.stats.zscore(df_stats[y_var])\n",
    "        \n",
    "        df_stats['rest'] = sp.stats.zscore(rest_timescales[i])\n",
    "        df_stats['task'] = sp.stats.zscore(task_timescales[i])\n",
    "        df_stats['age'] = sp.stats.zscore(df_behavior['age'])\n",
    "        df_stats['sex'] = df_behavior['sex']\n",
    "        df_stats = sm.add_constant(df_stats)\n",
    "        # if i == 0:\n",
    "            # print(df_stats.head())\n",
    "        \n",
    "        # Fit the model\n",
    "        results = smf.ols(formula='{0} ~ rest * task + age + C(sex)'.format(y_var), data=df_stats).fit()\n",
    "        # if i == 0:\n",
    "            # print(results.summary())\n",
    "        \n",
    "        for effect in ['rest', 'task', 'rest:task', 'age', 'C(sex)[T.1]']:\n",
    "            try:\n",
    "                effect_map.loc[i, effect] = results.params[effect]\n",
    "                pvals.loc[i, effect] = results.pvalues[effect]\n",
    "            except:\n",
    "                pass\n",
    "        effect_map.loc[i, 'rsquared'] = results.rsquared_adj\n",
    "        \n",
    "    return effect_map, pvals\n",
    "\n",
    "def detect_univariate_outliers(x, k=1.5):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (k * iqr)\n",
    "    upper_bound = q3 + (k * iqr)\n",
    "    outlier_labels = ((x < lower_bound) | (x > upper_bound)).astype(int)\n",
    "    \n",
    "    return outlier_labels\n",
    "\n",
    "def compute_r2(x, y):\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, np.newaxis]\n",
    "    if y.ndim == 1:\n",
    "        y = y[:, np.newaxis]\n",
    "\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    y_pred = regr.predict(x)\n",
    "    return r2_score(y, y_pred) * 100\n",
    "\n",
    "def winsorize_iqr(vector, k=1.5, inplace=False):\n",
    "    \"\"\"\n",
    "    Winsorizes a vector using the IQR method to handle outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    vector : array-like\n",
    "        Input data to be winsorized (list, numpy array, or pandas Series)\n",
    "    k : float, optional (default=1.5)\n",
    "        Multiplier for IQR to determine outlier thresholds\n",
    "    inplace : bool, optional (default=False)\n",
    "        If True, modifies the input vector in place (only works with mutable input)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    winsorized_vector : numpy array\n",
    "        Winsorized version of the input vector\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it isn't already\n",
    "    if not isinstance(vector, np.ndarray):\n",
    "        vector = np.array(vector)\n",
    "    \n",
    "    # Calculate quartiles and IQR\n",
    "    q1 = np.percentile(vector, 25)\n",
    "    q3 = np.percentile(vector, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate lower and upper bounds\n",
    "    lower_bound = q1 - k * iqr\n",
    "    upper_bound = q3 + k * iqr\n",
    "    \n",
    "    # Create a copy unless inplace is True and input is mutable\n",
    "    if inplace and isinstance(vector, np.ndarray):\n",
    "        winsorized_vector = vector\n",
    "    else:\n",
    "        winsorized_vector = vector.copy()\n",
    "    \n",
    "    # Winsorize the values\n",
    "    winsorized_vector[winsorized_vector < lower_bound] = lower_bound\n",
    "    winsorized_vector[winsorized_vector > upper_bound] = upper_bound\n",
    "    \n",
    "    return winsorized_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where data is stored\n",
    "indir = '/home/lindenmp/research_projects/nct_xr/data/int_deflections'\n",
    "which_data = 'HCP-YA'\n",
    "# which_data = 'HCP_D'\n",
    "# which_data = 'RBC-PNC'\n",
    "outdir = '/home/lindenmp/research_projects/nct_xr/results/int_deflections/{0}'.format(which_data.replace('_', ''))\n",
    "\n",
    "atlas = 'Schaefer4007'\n",
    "if atlas == 'Schaefer4007':\n",
    "    n_parcels = 400\n",
    "    n_nodes = 400\n",
    "elif atlas == 'Schaefer2007':\n",
    "    n_parcels = 200\n",
    "    n_nodes = 200\n",
    "elif atlas == 'Schaefer1007':\n",
    "    n_parcels = 100\n",
    "    n_nodes = 100\n",
    "    \n",
    "if which_data == 'HCP-YA':\n",
    "    tr = 0.720\n",
    "    # tasks = ['tfMRI_EMOTION_LR', 'tfMRI_GAMBLING_LR', 'tfMRI_LANGUAGE_LR', 'tfMRI_RELATIONAL_LR', 'tfMRI_SOCIAL_LR', 'tfMRI_WM_LR']\n",
    "    tasks = ['tfMRI_WM_LR', 'tfMRI_EMOTION_LR', 'tfMRI_LANGUAGE_LR', 'tfMRI_RELATIONAL_LR']\n",
    "\n",
    "    cog_measures = [\n",
    "        'PMAT24_A_CR', # fluid intelligence\n",
    "        'VSPLOT_TC', # spatial orientation\n",
    "        'ListSort_Unadj', # working memory\n",
    "        'DDisc_AUC_40K', # delay discounting\n",
    "        'Flanker_Unadj', # executive function\n",
    "    ]\n",
    "elif which_data == 'HCP_D':\n",
    "    tr = 0.800\n",
    "    # tasks = ['tfMRI_CARIT_PA', 'tfMRI_EMOTION_PA', 'tfMRI_GUESSING_PA']\n",
    "    tasks = ['tfMRI_CARIT_PA',]\n",
    "elif which_data == 'RBC-PNC':\n",
    "    tr = 3\n",
    "    tasks = ['frac2back',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot states on brain surface\n",
    "annot_dir = '/home/lindenmp/research_projects/nctpy/data'\n",
    "lh_annot_file = os.path.join(annot_dir, 'schaefer_parc', 'fsaverage5', 'lh.Schaefer2018_{0}Parcels_7Networks_order.annot'.format(n_parcels))\n",
    "rh_annot_file = os.path.join(annot_dir, 'schaefer_parc', 'fsaverage5', 'rh.Schaefer2018_{0}Parcels_7Networks_order.annot'.format(n_parcels))\n",
    "fsaverage = datasets.fetch_surf_fsaverage(mesh=\"fsaverage5\")\n",
    "cmap = \"viridis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = get_my_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parc_centroids = pd.read_csv(os.path.join(indir, 'Schaefer2018_{0}Parcels_7Networks_order_FSLMNI152_1mm.Centroid_RAS.csv'.format(n_parcels)), index_col=1)\n",
    "parc_centroids.drop(columns=['ROI Label'], inplace=True)\n",
    "print(parc_centroids.head())\n",
    "\n",
    "distance_matrix = distance.pdist(\n",
    "    parc_centroids, \"euclidean\"\n",
    ")  # get euclidean distances between nodes\n",
    "distance_matrix = distance.squareform(distance_matrix)  # reshape to square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectids = np.loadtxt(os.path.join(indir, '{0}_{1}_subjids.txt'.format(which_data.replace('_', ''), atlas)), dtype=str)\n",
    "n_subs = len(subjectids)\n",
    "print(n_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_axis = np.load(os.path.join(indir, 'schaefer{0}-7_sa-axis.npy'.format(n_parcels)))\n",
    "sa_axis_sort_idx = np.argsort(sa_axis)\n",
    "\n",
    "# myelin = np.load(os.path.join(indir, '{0}_{1}_myelin.npy'.format(which_data.replace('_', ''), atlas)))\n",
    "# myelin_mean = np.nanmean(myelin, axis=1)\n",
    "\n",
    "if which_data == 'HCP-YA':\n",
    "    which_task = 'rfMRIREST1LR'\n",
    "elif which_data == 'HCP_D':\n",
    "    which_task = 'rfMRIREST1PA'\n",
    "else:\n",
    "    which_task = 'RBC'\n",
    "\n",
    "rest_timescales = np.load(os.path.join(outdir, '{0}_{1}_{2}_timescales_acflag.npy'.format(which_data.replace('_', ''), atlas, which_task)))\n",
    "# rest_timescales = np.load(os.path.join(outdir, '{0}_{1}_{2}_timescales_alff.npy'.format(which_data.replace('_', ''), atlas, which_task)))\n",
    "\n",
    "# rest_timescales = np.log10(rest_timescales, out=np.zeros_like(rest_timescales), where=(rest_timescales != 0))\n",
    "\n",
    "rest_timescales_mean = np.nanmean(rest_timescales, axis=0)\n",
    "\n",
    "print(sa_axis.shape, rest_timescales.shape, rest_timescales_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_timescales = dict()\n",
    "task_timescales_mean = dict()\n",
    "subject_filter = dict()\n",
    "task_timescales_mean_all = np.zeros(n_parcels)\n",
    "for which_task in tasks:\n",
    "    print(which_task)\n",
    "    tsk_tscales = np.load(os.path.join(outdir, '{0}_{1}_{2}_timescales_acflag.npy'.format(which_data.replace('_', ''), atlas, which_task.replace('_', ''))))\n",
    "    # tsk_tscales = np.load(os.path.join(outdir, '{0}_{1}_{2}_timescales_alff.npy'.format(which_data.replace('_', ''), atlas, which_task.replace('_', ''))))\n",
    "    \n",
    "    # tsk_tscales = np.log10(tsk_tscales, out=np.zeros_like(tsk_tscales), where=(tsk_tscales != 0))\n",
    "    for i in np.arange(tsk_tscales.shape[0]):\n",
    "        tsk_tscales[i, :] = winsorize_iqr(tsk_tscales[i, :])\n",
    "    try:\n",
    "        subject_filter[which_task] = np.load(os.path.join(outdir, '{0}_{1}_{2}_subjectfilter.npy'.format(which_data.replace('_', ''), atlas, which_task.replace('_', ''))))\n",
    "        print(subject_filter[which_task].sum())\n",
    "        task_timescales_mean[which_task] = np.nanmean(tsk_tscales[~subject_filter[which_task], :], axis=0)\n",
    "    except:\n",
    "        task_timescales_mean[which_task] = np.nanmean(tsk_tscales, axis=0)\n",
    "    task_timescales[which_task] = tsk_tscales\n",
    "    task_timescales_mean_all += task_timescales_mean[which_task]\n",
    "\n",
    "task_timescales_mean_all = np.divide(task_timescales_mean_all, len(tasks))\n",
    "\n",
    "print(task_timescales_mean_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_timescales[which_task].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = surface_plot(\n",
    "#     data=sa_axis,\n",
    "#     lh_annot_file=lh_annot_file,\n",
    "#     rh_annot_file=rh_annot_file,\n",
    "#     fsaverage=fsaverage,\n",
    "#     order=\"lr\",\n",
    "#     cmap=\"viridis\",\n",
    "# )\n",
    "# f.savefig(os.path.join(outdir, 'sa_axis.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(index=np.arange(n_parcels))\n",
    "df_stats['rest'] = rest_timescales_mean\n",
    "df_stats['task'] = task_timescales_mean_all\n",
    "df_stats['SA'] = sa_axis\n",
    "df_stats = sm.add_constant(df_stats)\n",
    "results = smf.ols(formula='SA ~ rest * task', data=df_stats).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_deflections = compute_deflections(rest_timescales_mean, task_timescales_mean_all, nuisance_regression=True)\n",
    "int_deflections = task_timescales_mean_all - rest_timescales_mean\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(2*3, 1.75))\n",
    "reg_plot(sa_axis, rest_timescales_mean, xlabel='SA axis', ylabel='INTs (rest)', ax=ax[0], annotate='both', add_pval=False)\n",
    "reg_plot(sa_axis, task_timescales_mean_all, xlabel='SA axis', ylabel='INTs (task)', ax=ax[1], annotate='both', add_pval=False)\n",
    "reg_plot(sa_axis, int_deflections, xlabel='SA axis', ylabel='INTs (task-rest)', ax=ax[2], annotate='both', add_pval=False)\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()\n",
    "f.savefig(os.path.join(outdir, 'ints_deflections_sa_corr.svg'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = surface_plot(\n",
    "    data=rest_timescales_mean,\n",
    "    lh_annot_file=lh_annot_file,\n",
    "    rh_annot_file=rh_annot_file,\n",
    "    fsaverage=fsaverage,\n",
    "    order=\"lr\",\n",
    "    cmap=\"magma\",\n",
    ")\n",
    "f.savefig(os.path.join(outdir, 'ints_rest.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "f = surface_plot(\n",
    "    data=task_timescales_mean_all,\n",
    "    lh_annot_file=lh_annot_file,\n",
    "    rh_annot_file=rh_annot_file,\n",
    "    fsaverage=fsaverage,\n",
    "    order=\"lr\",\n",
    "    cmap=\"magma\",\n",
    ")\n",
    "f.savefig(os.path.join(outdir, 'ints_task.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "f = surface_plot(\n",
    "    data=int_deflections,\n",
    "    lh_annot_file=lh_annot_file,\n",
    "    rh_annot_file=rh_annot_file,\n",
    "    fsaverage=fsaverage,\n",
    "    order=\"lr\",\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "f.savefig(os.path.join(outdir, 'ints_deflections.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-level effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_task = tasks[0]\n",
    "print(which_task)\n",
    "\n",
    "if which_task == 'tfMRI_EMOTION_LR':\n",
    "    task_performance_measures = ['Emotion_Task_Acc', 'Emotion_Task_Median_RT']\n",
    "elif which_task == 'tfMRI_GAMBLING_LR':\n",
    "    task_performance_measures = ['Gambling_Task_Perc_Larger', 'Gambling_Task_Perc_Smaller']\n",
    "elif which_task == 'tfMRI_LANGUAGE_LR':\n",
    "    task_performance_measures = ['Language_Task_Acc', 'Language_Task_Median_RT']\n",
    "elif which_task == 'tfMRI_RELATIONAL_LR':\n",
    "    task_performance_measures = ['Relational_Task_Acc', 'Relational_Task_Median_RT']\n",
    "elif which_task == 'tfMRI_SOCIAL_LR':\n",
    "    task_performance_measures = ['Social_Task_Perc_Random', 'Social_Task_Perc_TOM']\n",
    "elif which_task == 'tfMRI_WM_LR' or which_task == 'tfMRI_WM_RL':\n",
    "    task_performance_measures = ['WM_Task_Acc', 'WM_Task_Median_RT']\n",
    "elif which_task == 'frac2back':\n",
    "    contrasts_list = ['0back', '1back', '2back']\n",
    "# elif which_task == 'tfMRI_CARIT_PA':\n",
    "    # task_performance_measures = ['WM_Task_Acc', 'WM_Task_Median_RT']\n",
    "    # contrasts_list = ['go', 'miss', 'nogoCRLose', 'nogoCRWin', 'nogoFALose', 'nogoFAWin']\n",
    "    # contrasts_list_short = ['go', 'nogo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(subjectids)\n",
    "\n",
    "if which_data == 'HCP-YA':\n",
    "    column_filter = task_performance_measures.copy()\n",
    "    column_filter.extend(cog_measures)\n",
    "    print(column_filter)\n",
    "\n",
    "    df_behavior = pd.read_csv('/mnt/storage_ssd_raid/research_data/HCP_YA/unrestricted_lindenmp_9_26_2022_16_52_14.csv', index_col=0)\n",
    "    df_behavior = df_behavior.loc[subjectids.astype(int)]\n",
    "    df_behavior_restricted = pd.read_csv('/mnt/storage_ssd_raid/research_data/HCP_YA/RESTRICTED_lindenmp_9_26_2022_16_42_3.csv', index_col=0)\n",
    "    df_behavior_restricted = df_behavior_restricted.loc[subjectids.astype(int)]\n",
    "    df_behavior['age'] = df_behavior_restricted['Age_in_Yrs']\n",
    "    df_behavior['sex'] = df_behavior['Gender'] == 'M'\n",
    "    df_behavior['sex'] = df_behavior['sex'].astype(int)\n",
    "\n",
    "    # for y_var in column_filter:\n",
    "        # df_behavior[y_var].fillna(np.nanmean(df_behavior[y_var]), inplace=True)\n",
    "\n",
    "    y_var = column_filter[0]\n",
    "    # y_var = 'age'\n",
    "    print(y_var)\n",
    "    if 'Acc' in y_var:\n",
    "        y_var_label = 'accuracy'\n",
    "    elif 'RT' in y_var:\n",
    "        y_var_label = 'RT'\n",
    "    else:\n",
    "        y_var_label = y_var\n",
    "\n",
    "    if y_var == 'WM_Task_Acc':\n",
    "        y_var_filter = df_behavior[y_var] >= 50\n",
    "    else:\n",
    "        y_var_filter = ~np.isnan(df_behavior[y_var].values)\n",
    "        # y_var_filter = np.zeros(n_subjects).astype(bool)\n",
    "        # y_var_filter[:] = True\n",
    "    print(np.sum(y_var_filter))\n",
    "        \n",
    "    if y_var == 'age':\n",
    "        nuis_covs = np.concatenate((df_behavior['sex'].values[:, np.newaxis],\n",
    "                                    np.ones((n_subjects, 1))\n",
    "                                    ), axis=1)\n",
    "    else:\n",
    "        nuis_covs = np.concatenate((sp.stats.zscore(df_behavior['age']).values[:, np.newaxis],\n",
    "                                    df_behavior['sex'].values[:, np.newaxis],\n",
    "                                    np.ones((n_subjects, 1))\n",
    "                                    ), axis=1)\n",
    "elif which_data == 'HCP_D':\n",
    "    df_behavior = pd.read_csv('/mnt/storage_ssd_raid/research_data/HCP_D/behavior/socdem01.txt', sep='\\t', header=0)\n",
    "    df_behavior = df_behavior.iloc[1:]\n",
    "    behavior_subjectids = list(df_behavior['src_subject_id'])\n",
    "    behavior_subjectids = ['sub-' + s + 'V1MR' for s in behavior_subjectids]\n",
    "    df_behavior.index = behavior_subjectids\n",
    "    df_behavior.index.name = 'subjectids'\n",
    "\n",
    "    y_var = 'interview_age'\n",
    "    y_var_label = 'age'\n",
    "    df_behavior = df_behavior.loc[:, [y_var, 'sex']]\n",
    "    df_behavior['sex'] = df_behavior['sex'] == 'M'\n",
    "    df_behavior['sex'] = df_behavior['sex'].astype(int)\n",
    "\n",
    "    df_behavior[y_var] = df_behavior[y_var].astype(float) / 12\n",
    "    df_behavior = df_behavior.loc[subjectids]\n",
    "    y_var_filter = np.zeros(n_subjects).astype(bool)\n",
    "    y_var_filter[:] = True\n",
    "    \n",
    "    nuis_covs = np.concatenate(((df_behavior['sex'] == 'M').astype(int).values[:, np.newaxis],\n",
    "                                np.ones((n_subjects, 1))\n",
    "                                ), axis=1)\n",
    "\n",
    "elif which_data == 'RBC-PNC':\n",
    "    df_behavior = pd.read_csv('/mnt/storage_ssd_raid/research_data/RBC/PNC/study-PNC_desc-participants.tsv', sep='\\t', header=0)\n",
    "    behavior_subjectids = list(df_behavior['participant_id'])\n",
    "    behavior_subjectids = ['sub-' + str(s) for s in behavior_subjectids]\n",
    "    df_behavior.index = behavior_subjectids\n",
    "    df_behavior.index.name = 'subjectids'\n",
    "\n",
    "    y_var = 'age'\n",
    "    y_var_label = 'age'\n",
    "    df_behavior = df_behavior.loc[:, [y_var, 'sex']]\n",
    "    df_behavior['sex'] = df_behavior['sex'] == 'Male'\n",
    "    df_behavior['sex'] = df_behavior['sex'].astype(int)\n",
    "\n",
    "    df_behavior[y_var] = df_behavior[y_var].astype(float)\n",
    "    df_behavior = df_behavior.loc[subjectids]\n",
    "    y_var_filter = np.zeros(n_subjects).astype(bool)\n",
    "    y_var_filter[:] = True\n",
    "\n",
    "    nuis_covs = np.concatenate((df_behavior['sex'].values[:, np.newaxis],\n",
    "                                np.ones((n_subjects, 1))\n",
    "                                ), axis=1)\n",
    "\n",
    "df_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuis_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_timescales_resid = nuis_reg(nuis_covs, rest_timescales)\n",
    "task_timescales_resid = nuis_reg(nuis_covs, task_timescales[which_task])\n",
    "# int_deflections = task_timescales[which_task] - rest_timescales\n",
    "# int_deflections = task_timescales_resid - rest_timescales_resid\n",
    "# int_deflections_resid = nuis_reg(rest_timescales_resid, int_deflections)\n",
    "\n",
    "# brain_data = rest_timescales_resid\n",
    "# brain_data = task_timescales_resid\n",
    "brain_data = task_timescales[which_task]\n",
    "# brain_data = int_deflections_resid\n",
    "\n",
    "# Fit models for each region, plot SA axis by beta value\n",
    "corr_map = np.zeros(n_parcels)\n",
    "p_map = np.zeros(n_parcels)\n",
    "for i in np.arange(n_parcels):\n",
    "    stats = sp.stats.pearsonr(brain_data[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "    corr_map[i] = stats[0]\n",
    "    p_map[i] = stats[1]\n",
    "\n",
    "    # corr_map[i] = compute_r2(brain_data[y_var_filter, i], df_behavior[y_var][y_var_filter].values)\n",
    "\n",
    "p_map = get_fdr_p(p_map)\n",
    "corr_map_filtered = corr_map.copy()\n",
    "# corr_map_filtered[p_map>0.05] = np.nan\n",
    "\n",
    "f2 = surface_plot(\n",
    "    data=corr_map_filtered,\n",
    "    lh_annot_file=lh_annot_file,\n",
    "    rh_annot_file=rh_annot_file,\n",
    "    fsaverage=fsaverage,\n",
    "    order=\"lr\",\n",
    "    cmap=\"coolwarm\",\n",
    "    # title_str='corr(int_deflections, behavior)'\n",
    ")\n",
    "f2.savefig(os.path.join(outdir, 'corr(int_deflections,behavior)_brainplot.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "# Get slope of the task-rest ~ SA axis per subject, regress slope on performance\n",
    "f, ax = plt.subplots(1, 1, figsize=(1.1, 1.1))\n",
    "reg_plot(sa_axis, corr_map, xlabel='SA axis', ylabel='corr(INTs, {0})'.format(y_var_label), ax=ax, annotate='spearman', add_pval=False)\n",
    "plt.show()\n",
    "f.savefig(os.path.join(outdir, 'int_deflections_task_performance_sa_corr_1.svg'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(3, 1.5))\n",
    "reg_plot(df_behavior[y_var][y_var_filter], brain_data[y_var_filter, np.argmin(corr_map)], xlabel=y_var_label, ylabel='INTs', ax=ax[0], annotate='both', add_pval=False)\n",
    "reg_plot(df_behavior[y_var][y_var_filter], brain_data[y_var_filter, np.argmax(corr_map)], xlabel=y_var_label, ylabel='INTs', ax=ax[1], annotate='both', add_pval=False)\n",
    "f.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr_map = np.zeros(n_subjects)\n",
    "for i in np.arange(n_subjects):\n",
    "    corr_map[i] = sp.stats.pearsonr(sa_axis, brain_data[i, :])[0]\n",
    "f, ax = plt.subplots(1, 1, figsize=(1.1, 1.1))\n",
    "reg_plot(df_behavior[y_var].values[y_var_filter], corr_map[y_var_filter], ylabel='corr(SA axis, INTs)', xlabel=y_var_label, ax=ax, annotate='spearman', add_pval=False)\n",
    "plt.show()\n",
    "f.savefig(os.path.join(outdir, 'int_deflections_task_performance_sa_corr_2.svg'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAM analysis of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LinearGAM, GammaGAM, s, f\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def fit_age_relationship(age, sex, y, model_type='gam', run_gridsearch=False):\n",
    "    \"\"\"\n",
    "    Fit either a GAM or linear regression to model the relationship between age and y \n",
    "    while controlling for sex. Returns age-based predictions at 1-month intervals.\n",
    "    \n",
    "    Parameters:\n",
    "        age (array-like): Age values in months\n",
    "        sex (array-like): Categorical sex values\n",
    "        y (array-like): Target variable\n",
    "        model_type (str): 'gam' or 'linear' regression\n",
    "        n_splines_range (range): Range of spline numbers to test (GAM only)\n",
    "        lam_range (array): Range of lambda values to test (GAM only)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains model, predictions, and parameters\n",
    "    \"\"\"\n",
    "\n",
    "    if model_type == 'gam':\n",
    "        # Create dataframe and drop missing values\n",
    "        df = pd.DataFrame({'age': age, 'sex': sex, 'y': y}).dropna()\n",
    "        df['sex'] = pd.Categorical(df['sex'])\n",
    "        n_age_steps = 100\n",
    "        # n_age_steps = np.arange(int(df['age'].min()), int(df['age'].max()) + 1, 1).shape[0]\n",
    "\n",
    "        n_splines = 3\n",
    "        if run_gridsearch:\n",
    "            # Fit GAM with current parameters\n",
    "            # lam = np.linspace(0.001, 0.1, 5)\n",
    "            lam = np.linspace(0.001, 1, 10)\n",
    "            # print(lam)\n",
    "            lams = [lam] * 2\n",
    "            model = LinearGAM(s(0, n_splines=n_splines, spline_order=n_splines-1) + f(1))\n",
    "            model.fit(df[['age', 'sex']], df['y'])\n",
    "            model.gridsearch(df[['age', 'sex']], df['y'], lam=lams, progress=False)\n",
    "        else:\n",
    "            lams = [0.1] * 2\n",
    "            model = LinearGAM(s(0, n_splines=n_splines, spline_order=n_splines-1) + f(1), lam=lams)\n",
    "            model.fit(df[['age', 'sex']], df['y'])\n",
    "\n",
    "        # Generate predictions\n",
    "        for i, term in enumerate(model.terms):\n",
    "            # print(term)\n",
    "            if i == 0:\n",
    "                age_grid = model.generate_X_grid(term=i, n=n_age_steps)\n",
    "                pred, confi = model.partial_dependence(term=i, X=age_grid, width=0.95)\n",
    "                # print(age_grid)\n",
    "                # print(pred)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # pred = pred - pred.mean()\n",
    "        # pred = sp.stats.zscore(pred)\n",
    "\n",
    "    elif model_type == 'linear':\n",
    "        n_age_steps = 100\n",
    "        # age_grid = np.arange(int(age.min()), int(age.max()) + 1, 1).reshape(-1, 1)\n",
    "        age = sp.stats.zscore(age)\n",
    "        age_grid = np.linspace(age.min(), age.max(), n_age_steps).reshape(-1, 1)\n",
    "        y = sp.stats.zscore(y)\n",
    "\n",
    "        age = age.reshape(-1, 1)\n",
    "        sex = sex.reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        # model.fit(sex, y)\n",
    "        # pred = model.predict(sex)\n",
    "        # y = y - pred\n",
    "        model.fit(sex, age)\n",
    "        pred = model.predict(sex)\n",
    "        age = age - pred\n",
    "\n",
    "        # Fit the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(age, y)\n",
    "        \n",
    "        # print(age_grid.shape)\n",
    "        pred = model.predict(age_grid).flatten()\n",
    "        pred = pred - pred.mean()\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'age': age_grid[:, 0],\n",
    "        'prediction': pred,\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': results_df,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'gam'\n",
    "run_gridsearch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "my_colors = get_my_colors()\n",
    "# colors = [my_colors['conch_shell'],\n",
    "#           my_colors['north_sea_green']]\n",
    "colors = ['orange',\n",
    "          'purple']\n",
    "cm = LinearSegmentedColormap.from_list(\"Custom\", colors, N=10)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "# reg_plot(sa_axis, age_resolved_change[:, 0], xlabel='sa', ylabel='age change', ax=ax, annotate='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_timescales_sorted = rest_timescales[:, sa_axis_sort_idx]\n",
    "task_timescales_sorted = task_timescales[which_task][:, sa_axis_sort_idx]\n",
    "\n",
    "predictions_rest = []\n",
    "age_resolved_change_rest = []\n",
    "predictions_task = []\n",
    "age_resolved_change_task = []\n",
    "predictions_deflections = []\n",
    "age_resolved_change_deflections = []\n",
    "\n",
    "age = df_behavior[y_var].values.copy()\n",
    "sex = df_behavior['sex'].values.copy()\n",
    "# print(sex)\n",
    "\n",
    "step_size = int(n_parcels/10)\n",
    "print(step_size)\n",
    "for i in np.arange(0, n_parcels, step_size):\n",
    "    rest_decile = rest_timescales_sorted[:, i:i+step_size].mean(axis=1)\n",
    "    task_decile = task_timescales_sorted[:, i:i+step_size].mean(axis=1)\n",
    "    deflections = task_decile - rest_decile\n",
    "    mean_back = deflections.mean()\n",
    "    deflections = np.squeeze(nuis_reg(rest_decile, deflections, use_sklearn=True))\n",
    "    deflections += mean_back\n",
    "                             \n",
    "    # rest\n",
    "    results = fit_age_relationship(age, sex, rest_decile, model_type=model_type, run_gridsearch=run_gridsearch)\n",
    "    preds = results['predictions']['prediction']\n",
    "    predictions_rest.append(preds)\n",
    "    age_resolved_change_rest.append(np.diff(preds))\n",
    "\n",
    "    # task\n",
    "    results = fit_age_relationship(age, sex, task_decile, model_type=model_type, run_gridsearch=run_gridsearch)\n",
    "    preds = results['predictions']['prediction']\n",
    "    predictions_task.append(preds)\n",
    "    age_resolved_change_task.append(np.diff(preds))\n",
    "    \n",
    "    # deflections\n",
    "    results = fit_age_relationship(age, sex, deflections, model_type=model_type, run_gridsearch=run_gridsearch)\n",
    "    preds = results['predictions']['prediction']\n",
    "    predictions_deflections.append(preds)\n",
    "    age_resolved_change_deflections.append(np.diff(preds))\n",
    "\n",
    "predictions_rest = np.asarray(predictions_rest)\n",
    "age_resolved_change_rest = np.asarray(age_resolved_change_rest)\n",
    "predictions_task = np.asarray(predictions_task)\n",
    "age_resolved_change_task = np.asarray(age_resolved_change_task)\n",
    "predictions_deflections = np.asarray(predictions_deflections)\n",
    "age_resolved_change_deflections = np.asarray(age_resolved_change_deflections)\n",
    "\n",
    "# print(predictions_rest.shape, age_resolved_change_rest.shape, predictions_task.shape, age_resolved_change_task.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(7.5, 2.5))\n",
    "for i in np.arange(int(n_parcels/step_size)):\n",
    "    ax[0].plot(results['predictions']['age'], predictions_rest[i], linewidth=1, alpha=1, color=cm(i))\n",
    "ax[0].set_title('rest')\n",
    "for i in np.arange(int(n_parcels/step_size)):\n",
    "    ax[1].plot(results['predictions']['age'], predictions_task[i], linewidth=1, alpha=1, color=cm(i))\n",
    "ax[1].set_title('task')\n",
    "for i in np.arange(int(n_parcels/step_size)):\n",
    "    ax[2].plot(results['predictions']['age'], predictions_deflections[i], linewidth=1, alpha=1, color=cm(i))\n",
    "ax[2].set_title('deflections')\n",
    "\n",
    "for this_ax in ax:\n",
    "    this_ax.set_xlabel('Age (years)')\n",
    "    this_ax.set_ylabel('INTs (GAM prediction)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_change = np.abs(age_resolved_change_task) - np.abs(age_resolved_change_rest)\n",
    "# relative_change = age_resolved_change_task - age_resolved_change_rest\n",
    "print(relative_change.shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(5, 2.5))\n",
    "# ax[0].plot(results['predictions']['age'][1:], age_resolved_change_rest[-1], linewidth=2, alpha=1, linestyle='--', color=cm(9))\n",
    "# ax[0].plot(results['predictions']['age'][1:], age_resolved_change_task[-1], linewidth=2, alpha=1, color=cm(9))\n",
    "ax[0].plot(results['predictions']['age'], predictions_rest[0], linewidth=2, alpha=1, linestyle='--', color=cm(0))\n",
    "\n",
    "ax[0].plot(results['predictions']['age'], predictions_task[0], linewidth=2, alpha=1, color=cm(0))\n",
    "ax[0].plot(results['predictions']['age'], predictions_rest[-1], linewidth=2, alpha=1, linestyle='--', color=cm(9))\n",
    "ax[0].plot(results['predictions']['age'], predictions_task[-1], linewidth=2, alpha=1, color=cm(9))\n",
    "# ax[0].axhline(y=0, color='k', linestyle='--')\n",
    "\n",
    "ax[1].plot(results['predictions']['age'][1:], relative_change[0, :], color=cm(0), linewidth=2, label='sensorimotor')\n",
    "ax[1].plot(results['predictions']['age'][1:], relative_change[-1, :], color=cm(10), linewidth=2, label='association')\n",
    "ax[1].axhline(y=0, color='k', linestyle='--')\n",
    "ax[1].set_xlabel('Age (years)')\n",
    "ax[1].set_ylabel('mean(age change, task-rest)')\n",
    "# ax[1].grid(True)\n",
    "# ax[1].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export data for Bart\n",
    "# df_rest = pd.DataFrame()\n",
    "# df_rest['subject_id'] = subjectids\n",
    "# df_rest.set_index('subject_id', inplace=True)\n",
    "# df_rest['age'] = df_behavior[y_var].values.copy()\n",
    "# df_rest['sex'] = df_behavior['sex'].values.copy()\n",
    "# counter = 1\n",
    "# for i in np.arange(0, n_parcels, step_size):\n",
    "#     df_rest['SA_dec_{0}'.format(counter)] = rest_timescales_sorted[:, i:i+step_size].mean(axis=1)\n",
    "#     counter += 1\n",
    "# df_rest.to_csv(os.path.join(outdir, 'df_rest_larsen.csv'))\n",
    "\n",
    "# df_task = pd.DataFrame()\n",
    "# df_task['subject_id'] = subjectids\n",
    "# df_task.set_index('subject_id', inplace=True)\n",
    "# df_task['age'] = df_behavior[y_var].values.copy()\n",
    "# df_task['sex'] = df_behavior['sex'].values.copy()\n",
    "# counter = 1\n",
    "# for i in np.arange(0, n_parcels, step_size):\n",
    "#     df_task['SA_dec_{0}'.format(counter)] = task_timescales_sorted[:, i:i+step_size].mean(axis=1)\n",
    "#     counter += 1\n",
    "# df_task.to_csv(os.path.join(outdir, 'df_task_larsen.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_val = 0.2\n",
    "# lower_q = sa_axis < np.quantile(sa_axis, q=q_val)\n",
    "# upper_q = sa_axis > np.quantile(sa_axis, q=1-q_val)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(4.5, 2))\n",
    "# ax[0].plot(results['predictions']['age'][1:], np.mean(age_resolved_change_rest[lower_q, :], axis=0), 'r-', linewidth=2, label='rest')\n",
    "# ax[0].plot(results['predictions']['age'][1:], np.mean(age_resolved_change_task[lower_q, :], axis=0), 'b-', linewidth=2, label='task')\n",
    "# ax[0].set_title('Sensorimotor')\n",
    "# ax[1].plot(results['predictions']['age'][1:], np.mean(age_resolved_change_rest[upper_q, :], axis=0), 'r-', linewidth=2, label='rest')\n",
    "# ax[1].plot(results['predictions']['age'][1:], np.mean(age_resolved_change_task[upper_q, :], axis=0), 'b-', linewidth=2, label='task')\n",
    "# ax[1].set_title('Association')\n",
    "# for this_ax in ax:\n",
    "#     this_ax.set_xlabel('Age (years)')\n",
    "#     this_ax.set_ylabel('mean(age change)')\n",
    "#     this_ax.grid(True)\n",
    "#     this_ax.legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rest = []\n",
    "age_resolved_change_rest = []\n",
    "predictions_task = []\n",
    "age_resolved_change_task = []\n",
    "\n",
    "for i in tqdm(np.arange(n_parcels)):\n",
    "    # rest\n",
    "    results = fit_age_relationship(age, sex, rest_timescales[:, i], model_type=model_type, run_gridsearch=run_gridsearch)\n",
    "    preds = results['predictions']['prediction']\n",
    "    predictions_rest.append(preds)\n",
    "    age_resolved_change_rest.append(np.diff(preds))\n",
    "    \n",
    "    # task\n",
    "    results = fit_age_relationship(age, sex, task_timescales[which_task][:, i], model_type=model_type, run_gridsearch=run_gridsearch)\n",
    "    preds = results['predictions']['prediction']\n",
    "    predictions_task.append(preds)\n",
    "    age_resolved_change_task.append(np.diff(preds))\n",
    "\n",
    "predictions_rest = np.asarray(predictions_rest)\n",
    "age_resolved_change_rest = np.asarray(age_resolved_change_rest)\n",
    "predictions_task = np.asarray(predictions_task)\n",
    "age_resolved_change_task = np.asarray(age_resolved_change_task)\n",
    "print(predictions_rest.shape, age_resolved_change_rest.shape, predictions_task.shape, age_resolved_change_task.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa_axis_corr = []\n",
    "# for i in np.arange(age_resolved_change_rest.shape[1]):\n",
    "#     sa_axis_corr.append(sp.stats.pearsonr(sa_axis, age_resolved_change_rest[:, i])[0])\n",
    "# sa_axis_corr = np.asarray(sa_axis_corr)\n",
    "# print(sa_axis_corr.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "# ax.plot(results['predictions']['age'][1:], sa_axis_corr, 'k-', linewidth=2)\n",
    "# ax.set_xlabel('Age (years)')\n",
    "# ax.set_ylabel('corr(SA axis, age effect)')\n",
    "# # ax.grid(True)\n",
    "# # fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "\n",
    "sa_axis_corr = []\n",
    "for i in np.arange(age_resolved_change_rest.shape[1]):\n",
    "    sa_axis_corr.append(sp.stats.pearsonr(sa_axis, age_resolved_change_rest[:, i])[0])\n",
    "    # sa_axis_corr.append(sp.stats.pearsonr(sa_axis, np.abs(age_resolved_change_rest[:, i]))[0])\n",
    "sa_axis_corr = np.asarray(sa_axis_corr)\n",
    "# sa_axis_corr = sp.stats.zscore(sa_axis_corr)\n",
    "ax.plot(results['predictions']['age'][1:], sa_axis_corr, 'r-', linewidth=2, label='rest')\n",
    "\n",
    "sa_axis_corr = []\n",
    "for i in np.arange(age_resolved_change_task.shape[1]):\n",
    "    sa_axis_corr.append(sp.stats.pearsonr(sa_axis, age_resolved_change_task[:, i])[0])\n",
    "    # sa_axis_corr.append(sp.stats.pearsonr(sa_axis, np.abs(age_resolved_change_task[:, i]))[0])\n",
    "sa_axis_corr = np.asarray(sa_axis_corr)\n",
    "# sa_axis_corr = sp.stats.zscore(sa_axis_corr)\n",
    "ax.plot(results['predictions']['age'][1:], sa_axis_corr, 'b-', linewidth=2, label='task')\n",
    "\n",
    "ax.set_xlabel('Age (years)')\n",
    "ax.set_ylabel('corr(SA axis, age effect)')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset specific analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HCP YA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_data == 'HCP-YA':\n",
    "    n_cols = 3\n",
    "    f, ax = plt.subplots(1, n_cols, figsize=(2*n_cols, 2))\n",
    "    plot_col = 0\n",
    "\n",
    "    # version 1, deflections\n",
    "    # int_deflections = task_timescales - rest_timescales\n",
    "    # int_deflections_resid = np.zeros(int_deflections.shape)\n",
    "    # for i in np.arange(n_subjects):\n",
    "    #     int_deflections_resid[i, :] = nuis_reg(rest_timescales[i, :], int_deflections[i, :], use_sklearn=True)[:, 0]\n",
    "        \n",
    "    # corr_map = np.zeros(n_parcels)\n",
    "    # p_map = np.zeros(n_parcels)\n",
    "    # for i in np.arange(n_parcels):\n",
    "    #     stats = sp.stats.pearsonr(int_deflections[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "    #     # stats = sp.stats.pearsonr(int_deflections_resid[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "    #     corr_map[i] = stats[0]\n",
    "    #     p_map[i] = stats[1]\n",
    "\n",
    "    # reg_plot(sa_axis, corr_map, xlabel='SA axis', ylabel='corr(INTs_deflection, {0})'.format(y_var), ax=ax[plot_col], annotate='both', order=1, add_pval=False)  # 'coef({0}, {1})'.format(effect,y_var)\n",
    "\n",
    "    # version 2, interaction\n",
    "    # int_deflections = task_timescales_resid - rest_timescales_resid\n",
    "    int_deflections = task_timescales[which_task] - rest_timescales\n",
    "    corr_map_rest = np.zeros(n_parcels)\n",
    "    corr_map_task = np.zeros(n_parcels)\n",
    "    corr_map_delta = np.zeros(n_parcels)\n",
    "    for i in np.arange(n_parcels):\n",
    "        stats = sp.stats.pearsonr(rest_timescales_resid[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "        corr_map_rest[i] = stats[0]\n",
    "        \n",
    "        stats = sp.stats.pearsonr(task_timescales_resid[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "        corr_map_task[i] = stats[0]\n",
    "        \n",
    "        stats = sp.stats.pearsonr(int_deflections[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "        corr_map_delta[i] = stats[0]\n",
    "\n",
    "    df_stats = pd.DataFrame(index=np.arange(n_parcels))\n",
    "    df_stats['rest'] = corr_map_rest\n",
    "    df_stats['task'] = corr_map_task\n",
    "    df_stats['SA'] = sa_axis\n",
    "    df_stats = sm.add_constant(df_stats)\n",
    "    results = smf.ols(formula='SA ~ rest : task', data=df_stats).fit()\n",
    "\n",
    "    sns.regplot(x=sa_axis, y=corr_map_rest, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='rest', line_kws={'linestyle': '-'}, color=my_colors['north_sea_green'], order=1)\n",
    "    sns.regplot(x=sa_axis, y=corr_map_task, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='task', line_kws={'linestyle': '--'}, color=my_colors['north_sea_green'], order=1)\n",
    "    ax[plot_col].set_xlabel('SA axis')\n",
    "    ax[plot_col].set_ylabel('corr(INTs, {0})'.format(y_var))\n",
    "    ax[plot_col].set_title('t = {:.2f}, p = {:.2f}'.format(np.abs(results.tvalues['rest:task']), results.pvalues['rest:task']))\n",
    "    ax[plot_col].legend()\n",
    "\n",
    "    plot_col += 1\n",
    "\n",
    "    q_val = 0.2\n",
    "    lower_q = sa_axis < np.quantile(sa_axis, q=q_val)\n",
    "    upper_q = sa_axis > np.quantile(sa_axis, q=1-q_val)\n",
    "\n",
    "    rest_timescales_mean_bin = rest_timescales_resid[:, lower_q].mean(axis=1)\n",
    "    task_timescales_mean_bin = task_timescales_resid[:, lower_q].mean(axis=1)\n",
    "    y = df_behavior[y_var][y_var_filter]\n",
    "    x = rest_timescales_mean_bin[y_var_filter]\n",
    "    sns.regplot(x=x, y=y, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='rest', line_kws={'linestyle': '-'}, color='orange', order=1)\n",
    "    r_rest = sp.stats.pearsonr(x, y)[0]\n",
    "    x = task_timescales_mean_bin[y_var_filter]\n",
    "    sns.regplot(x=x, y=y, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='task', line_kws={'linestyle': '--'}, color='orange', order=1)\n",
    "    r_task = sp.stats.pearsonr(x, y)[0]\n",
    "\n",
    "    ax[plot_col].set_xlabel('INTs')\n",
    "    ax[plot_col].set_ylabel(y_var)\n",
    "    ax[plot_col].set_title('Sensorimotor')\n",
    "    # ax[plot_col].set_title('Sensorimotor\\nr_rest={:.2f}, r_task={:.2f}'.format(r_rest, r_task))\n",
    "    # ax[plot_col].set_title('Sensorimotor (bottom {0}%)'.format(int(q_val*100)))\n",
    "    ax[plot_col].legend()\n",
    "    plot_col += 1\n",
    "\n",
    "    rest_timescales_mean_bin = rest_timescales_resid[:, upper_q].mean(axis=1)\n",
    "    task_timescales_mean_bin = task_timescales_resid[:, upper_q].mean(axis=1)\n",
    "    x = rest_timescales_mean_bin[y_var_filter]\n",
    "    sns.regplot(x=x, y=y, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='rest', line_kws={'linestyle': '-'}, color='purple', order=1)\n",
    "    r_rest = sp.stats.pearsonr(x, y)[0]\n",
    "    x = task_timescales_mean_bin[y_var_filter]\n",
    "    sns.regplot(x=x, y=y, ax=ax[plot_col], scatter=False, marker='.', scatter_kws={\"s\": 1}, label='task', line_kws={'linestyle': '--'}, color='purple', order=1)\n",
    "    r_task = sp.stats.pearsonr(x, y)[0]\n",
    "\n",
    "    ax[plot_col].set_xlabel('INTs')\n",
    "    ax[plot_col].set_ylabel(y_var)\n",
    "    ax[plot_col].set_title('Association')\n",
    "    # ax[plot_col].set_title('Association\\nr_rest={:.2f}, r_task={:.2f}'.format(r_rest, r_task))\n",
    "    # ax[plot_col].set_title('Association (top {0}%)'.format(int(q_val*100)))\n",
    "    ax[plot_col].legend()\n",
    "\n",
    "    for this_ax in ax.reshape(-1):\n",
    "        sns.despine(right=True, top=True, ax=this_ax)\n",
    "\n",
    "    # f.suptitle(which_task)\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(os.path.join(outdir, 'interaction_plot.svg'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "    f2 = surface_plot(\n",
    "        data=corr_map_delta,\n",
    "        lh_annot_file=lh_annot_file,\n",
    "        rh_annot_file=rh_annot_file,\n",
    "        fsaverage=fsaverage,\n",
    "        order=\"lr\",\n",
    "        cmap=\"coolwarm\",\n",
    "        # title_str='corr(int_deflections, behavior)'\n",
    "    )\n",
    "    f2.savefig(os.path.join(outdir, 'interaction_plot_brain.png'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_data == 'HCP-YA':\n",
    "    heatmap_data = np.zeros((len(column_filter), 5))\n",
    "    heatmap_data_pval = np.zeros((len(column_filter), 5))\n",
    "\n",
    "    for idx, y_var in enumerate(column_filter):\n",
    "        print(y_var)\n",
    "        y_var_filter = ~np.isnan(df_behavior[y_var].values)\n",
    "        print(np.sum(y_var_filter))\n",
    "        \n",
    "        corr_map_rest = np.zeros(n_parcels)\n",
    "        corr_map_task = np.zeros(n_parcels)\n",
    "        for i in np.arange(n_parcels):\n",
    "            stats = sp.stats.pearsonr(rest_timescales_resid[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "            corr_map_rest[i] = stats[0]\n",
    "            \n",
    "            stats = sp.stats.pearsonr(task_timescales_resid[y_var_filter, i], df_behavior[y_var][y_var_filter])\n",
    "            corr_map_task[i] = stats[0]\n",
    "\n",
    "        df_stats = pd.DataFrame(index=np.arange(n_parcels))\n",
    "        df_stats['rest'] = corr_map_rest\n",
    "        df_stats['task'] = corr_map_task\n",
    "        df_stats['SA'] = sa_axis\n",
    "        df_stats = sm.add_constant(df_stats)\n",
    "        results = smf.ols(formula='SA ~ rest : task', data=df_stats).fit()\n",
    "        \n",
    "        heatmap_data[idx, 0] = results.tvalues['rest:task']\n",
    "        heatmap_data_pval[idx, 0] = results.pvalues['rest:task']\n",
    "\n",
    "        y = df_behavior[y_var][y_var_filter]\n",
    "\n",
    "        rest_timescales_mean_bin = rest_timescales_resid[:, lower_q].mean(axis=1)\n",
    "        task_timescales_mean_bin = task_timescales_resid[:, lower_q].mean(axis=1)\n",
    "        heatmap_data[idx, 1] = sp.stats.pearsonr(rest_timescales_mean_bin[y_var_filter], y)[0]\n",
    "        heatmap_data[idx, 2] = sp.stats.pearsonr(task_timescales_mean_bin[y_var_filter], y)[0]\n",
    "\n",
    "        rest_timescales_mean_bin = rest_timescales_resid[:, upper_q].mean(axis=1)\n",
    "        task_timescales_mean_bin = task_timescales_resid[:, upper_q].mean(axis=1)\n",
    "        heatmap_data[idx, 3] = sp.stats.pearsonr(rest_timescales_mean_bin[y_var_filter], y)[0]\n",
    "        heatmap_data[idx, 4] = sp.stats.pearsonr(task_timescales_mean_bin[y_var_filter], y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_data == 'HCP-YA':\n",
    "    # f, ax = plt.subplots(3, 1, figsize=(1, 2))\n",
    "    f, ax = plt.subplots(3, 1, figsize=(1.25, 2))\n",
    "    # heatmap_labels = [my_str.split('_')[0] for my_str in cog_measures]\n",
    "    heatmap_labels = [my_str.split('_')[0] for my_str in column_filter]\n",
    "    heatmap_labels[0] = 'accuracy'\n",
    "    heatmap_labels[1] = 'RT'\n",
    "    print(heatmap_labels)\n",
    "\n",
    "    markerline, stemlines, baseline = ax[0].stem(np.abs(heatmap_data[:, 0]))\n",
    "    plt.setp(stemlines, color=my_colors['north_sea_green'])\n",
    "    plt.setp(markerline, markersize=2, markeredgecolor=my_colors['north_sea_green'], markeredgewidth=0.5, markerfacecolor=my_colors['north_sea_green'])\n",
    "    plt.setp(baseline, visible=False)\n",
    "    ax[0].axhline(y=0, color='grey', linestyle=':')\n",
    "    ax[0].set_ylabel('t-statistic')\n",
    "    ax[0].set_xticklabels('')\n",
    "    ax[0].set_xticks([])\n",
    "\n",
    "    markerline, stemlines, baseline = ax[1].stem(np.arange(len(heatmap_labels))-0.1, heatmap_data[:, 1], linefmt='-', label='rest')\n",
    "    plt.setp(stemlines, color='orange')\n",
    "    plt.setp(markerline, markersize=2, markeredgecolor='orange', markeredgewidth=0.5, markerfacecolor='orange')\n",
    "    plt.setp(baseline, visible=False)\n",
    "    markerline, stemlines, baseline = ax[1].stem(np.arange(len(heatmap_labels))+0.1, heatmap_data[:, 2], linefmt='--', label='task')\n",
    "    plt.setp(stemlines, color='orange')\n",
    "    plt.setp(markerline, markersize=2, markeredgecolor='orange', markeredgewidth=0.5, markerfacecolor='orange')\n",
    "    plt.setp(baseline, visible=False)\n",
    "    ax[1].axhline(y=0, color='grey', linestyle=':')\n",
    "    ax[1].set_ylabel('slope (r)')\n",
    "    ax[1].set_xticklabels('')\n",
    "    ax[1].set_xticks([])\n",
    "\n",
    "    markerline, stemlines, baseline = ax[2].stem(np.arange(len(heatmap_labels))-0.1, heatmap_data[:, 3], linefmt='-', label='rest')\n",
    "    plt.setp(stemlines, color='purple')\n",
    "    plt.setp(markerline, markersize=2, markeredgecolor='purple', markeredgewidth=0.5, markerfacecolor='purple')\n",
    "    plt.setp(baseline, visible=False)\n",
    "    markerline, stemlines, baseline = ax[2].stem(np.arange(len(heatmap_labels))+0.1, heatmap_data[:, 4], linefmt='--', label='task')\n",
    "    plt.setp(stemlines, color='purple')\n",
    "    plt.setp(markerline, markersize=2, markeredgecolor='purple', markeredgewidth=0.5, markerfacecolor='purple')\n",
    "    plt.setp(baseline, visible=False)\n",
    "    ax[2].axhline(y=0, color='grey', linestyle=':')\n",
    "    ax[2].set_ylabel('slope (r)')\n",
    "    ax[2].set_xticks(np.arange(len(heatmap_labels)))\n",
    "    ax[2].set_xticklabels(heatmap_labels, rotation=90, ha='center')\n",
    "\n",
    "    # f.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(os.path.join(outdir, 'interaction_stemplot.svg'), dpi=600, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nct_xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
